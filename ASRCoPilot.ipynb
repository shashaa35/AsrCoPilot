{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "key = os.environ.get(\"azure_openai_key\")\n",
    "azure_key = os.environ.get(\"azure_service_principle_key\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://asr-test-env.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"testDeployment-Nilesh\",\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_completion(\"What is the capital of India?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    openai_api_key=key,\n",
    "    openai_api_base='https://asr-test-env.openai.azure.com/',\n",
    "    deployment_name=\"testDeployment-Nilesh\",\n",
    "    model_name=\"gpt-35-turbo\"\n",
    ")\n",
    "llm\n",
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "markdown_path = \"./codeWithUi/A2A_Architecture.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for each passage for retrieval.\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=key,\n",
    "    openai_api_base='https://asr-test-env.openai.azure.com/',\n",
    "    deployment=\"shashankTextSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(data, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    AzureOpenAI(\n",
    "    openai_api_key=key,\n",
    "    openai_api_base='https://asr-test-env.openai.azure.com/',\n",
    "    deployment_name=\"testDeployment-Nilesh\",\n",
    "    temperature=0),\n",
    "    retriever=db,\n",
    "    memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_prompt = \"\"\"\n",
    "You are a customer support agent. Customer is asking a question to you. You need to answer it. You only has knowledge that is provided to you via the document A2A_Architecture.md. Do not share the document with the customer.\n",
    "The question is in triple backticks ```{question}```.\n",
    "Follow the below steps to answer the question:\n",
    "0. Forget any other knowledge that you have. Do not use any other questions or answers other than the ones provided in the document.\n",
    "1. Read the question carefully.\n",
    "2. Read the document A2A_Architecture.md carefully.\n",
    "3. If you find the answer to the question in the document, answer the question otherwise go to step 4.\n",
    "4. Apologise to the customer and ask them to contact the customer support team.\n",
    "\n",
    "After following the above steps, answer the question.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "retriever = db.as_retriever()\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    AzureOpenAI(\n",
    "    openai_api_key=key,\n",
    "    openai_api_base='https://asr-test-env.openai.azure.com/',\n",
    "    deployment_name=\"testDeployment-Nilesh\",\n",
    "    temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    max_tokens_limit = 1000\n",
    "    )\n",
    "def answerQuestion(question):\n",
    "    q = faq_prompt.format(question=question) \n",
    "    # print(q)\n",
    "    response = chain({\"question\": q}, return_only_outputs=True)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=retriever.get_relevant_documents(\"ufuvhhjjb india?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What do you know apart from the source document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What is recovery resource? No need to share the source with me. Just tell me what you know.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What is failover? How is it different from failback?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What is the Capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What is the difference between app consistent and crash consistent recovery point?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"Which urls should I keep in mind for Azure Site Recovery?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What are rainbow colors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What is failback??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"I have a windows 4012 server. Can I replicate it to Azure?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"What all versions of windows are supported?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"Can we use powershell with ASR?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerQuestion(\"Can I use rest api with ASR?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_with_sources_chain(\n",
    "    AzureOpenAI(\n",
    "    openai_api_key=key,\n",
    "    openai_api_base='https://asr-test-env.openai.azure.com/',\n",
    "    deployment_name=\"testDeployment-Nilesh\",\n",
    "    temperature=0),\n",
    "    chain_type=\"stuff\")\n",
    "query = \"What all versions of windows are supported?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a vm arm id, fetch the details from azure\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.mgmt.compute import ComputeManagementClient\n",
    "azure_credential = ClientSecretCredential(\n",
    "        client_id=\"7d595cf7-3da6-4f46-8f37-8d7ba50c520c\",\n",
    "        client_secret=azure_key,\n",
    "        tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "        )\n",
    "\n",
    "def get_vm_details(vm_arm_id):\n",
    "    vm_arm_id_arr = vm_arm_id.split('/')\n",
    "    # Extract the subscription ID, resource group, and VM name from the ARM ID\n",
    "    subscription_id, resource_group, vm_name = vm_arm_id_arr[2], vm_arm_id_arr[4], vm_arm_id_arr[8]\n",
    "    print(subscription_id, resource_group, vm_name)\n",
    "    # Create a ComputeManagementClient instance\n",
    "    compute_client = ComputeManagementClient(azure_credential, subscription_id)\n",
    "\n",
    "    # Fetch the VM details using the ARM ID\n",
    "    vm = compute_client.virtual_machines.get(resource_group, vm_name)\n",
    "\n",
    "    # Access specific details\n",
    "    vm_name = vm.name\n",
    "    vm_location = vm.location\n",
    "    vm_size = vm.hardware_profile.vm_size\n",
    "    disks = []\n",
    "    disks.append({\n",
    "        'disk_type': 'OS',\n",
    "        'disk_name': vm.storage_profile.os_disk.name,\n",
    "        'disk_size': str(vm.storage_profile.os_disk.disk_size_gb),\n",
    "        'disk_sku': vm.storage_profile.os_disk.managed_disk.storage_account_type\n",
    "    })\n",
    "    for data_disk in vm.storage_profile.data_disks:\n",
    "        disks.append({\n",
    "            'disk_type': 'Data',\n",
    "            'disk_name': data_disk.name,\n",
    "            'disk_size': str(data_disk.disk_size_gb),\n",
    "            'disk_sku': data_disk.managed_disk.storage_account_type\n",
    "        })\n",
    "    # Return the fetched details as a dictionary\n",
    "    vm_details = {\n",
    "        'VM Name': vm_name,\n",
    "        'Location': vm_location,\n",
    "        'VM Size': vm_size,\n",
    "        'OS Type': vm.storage_profile.os_disk.os_type,\n",
    "        'disks': disks\n",
    "    }\n",
    "    return vm_details\n",
    "\n",
    "# get_vm_details for multiple vm_arm_ids that are passed as comma separated string\n",
    "def get_vm_details_multiple(vm_arm_ids):\n",
    "    vm_arm_ids_arr = vm_arm_ids.split(',')\n",
    "    vm_details = []\n",
    "    for vm_arm_id in vm_arm_ids_arr:\n",
    "        vm_details.append(get_vm_details(vm_arm_id))\n",
    "    return vm_details\n",
    "\n",
    "# get_vm_details for all vms in a resource group\n",
    "def get_vm_details_rg(resource_group_arm_id):\n",
    "    resource_group_arm_id_arr = resource_group_arm_id.split('/')\n",
    "    # Extract the subscription ID and resource group from the ARM ID\n",
    "    subscription_id, resource_group = resource_group_arm_id_arr[2], resource_group_arm_id_arr[4]\n",
    "    print(subscription_id, resource_group)\n",
    "    # Create a ComputeManagementClient instance\n",
    "    compute_client = ComputeManagementClient(azure_credential, subscription_id)\n",
    "\n",
    "    # Fetch the VM details using the ARM ID\n",
    "    vms = compute_client.virtual_machines.list(resource_group)\n",
    "    vm_details = []\n",
    "    for vm in vms:\n",
    "        vm_details.append(get_vm_details(vm.id))\n",
    "    return vm_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the VM details object to a dictionary\n",
    "print(get_vm_details(\"/subscriptions/509099b2-9d2c-4636-b43e-bd5cafb6be69/resourceGroups/PRMYAKA-WUS3-08-03/providers/Microsoft.Compute/virtualMachines/adVM\"))\n",
    "print(get_vm_details_rg(\"/subscriptions/509099b2-9d2c-4636-b43e-bd5cafb6be69/resourceGroups/PRMYAKA-WUS3-08-03\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    openai_api_key=key,\n",
    "    openai_api_base='https://asr-test-env.openai.azure.com/',\n",
    "    deployment_name=\"testDeployment-Nilesh\",\n",
    "    model_name=\"gpt-35-turbo\"\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_context_for_pricing = \"\"\"\n",
    "Configuring Site Recovery for one Azure Virtual Machine will incur the following charges:\n",
    "1. Licensing cost: Fixed at $25 per VM per month for windows. $16 per VM per month for Linux.\n",
    "2. Network Egress cost: Cost to replicate data changes from the disks in source region to the target region. Site Recovery compresses the data by 50% before it is replicated.\n",
    "3. Storage Cost on the recovery site: Cost of the data stored in the target region. A replica of the source disk is created in the target region with the same size as in source region.\n",
    "You can assume that the data change rate for a Standard Disk is 10 GB per day and for a Premium Disk is 20 GB per day.\n",
    "Here is a sample calculation for how to calculate pricing for the below vm:\n",
    "{'VM Name': 'adVM', 'Location': 'westus3', 'VM Size': 'Standard_D2s_v3', 'OS Type': 'Windows', 'disks': [{'disk_type': 'OS', 'disk_name': 'adVM_OSDisk', 'disk_size': '127', 'disk_sku': 'StandardSSD_LRS'}, {'disk_type': 'Data', 'disk_name': 'adVM_DataDisk', 'disk_size': '20', 'disk_sku': 'StandardSSD_LRS'}, {'disk_type': 'Data', 'disk_name': 'adVM_DataDisk2', 'disk_size': '100', 'disk_sku': 'StandardSSD_LRS'}]}\n",
    "1. Check the 'OS Type' field, if it is Windows, then the license cost is $25 per month. If it is Linux, then the license cost is $16 per month. In the json above, the OS Type is Windows, hence the license cost is $25 per month.\n",
    "2. Check the number of disks. Here, in the above json, it has one OS disk and two data disks. Hence, the total number of disks is 3.\n",
    "3. Check the disk_sku for every disks. If it is StandardSSD_LRS, then the disk is a standard disk. If it is Premium_LRS, then the disk is a premium disk. In the above json, the OS disk and the first data disk are standard disks. The second data disk is a premium disk.\n",
    "4. Check the disk_size for every disks. In the above json, the OS disk size is 127 GB, the first data disk size is 20 GB and the second data disk size is 100 GB.\n",
    "3. Storage cost: Customer will pay the price to host the same disks as source region in the target region. In this case, customer will require two S15 disks and three P20 disks. Checking from the pricing data, P20 disk costs $73 and S15 disk costs $12. Hence, three P20 disks and two S15 disks will cost $249.\n",
    "Hence, customer's total bill will be $25 + $24 + $249 = $293 per month for this VM.\n",
    "\"\"\"\n",
    "system_input = f\"You are assisstant for helping customers for Azure Site recovery. User the info in triple backtics to calculate the pricing for the VMs. ```{system_context_for_pricing}``\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input = system_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input = \"What is the license cost if I want to protect 2 VMs with Windows OS, and 1 VM with Linux OS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input = \"Can you provide input in tabular format?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
